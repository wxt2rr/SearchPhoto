import os
import sys
import pickle
import faiss
import numpy as np
import time
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
from transformers import CLIPProcessor, CLIPModel, ChineseCLIPProcessor, ChineseCLIPModel
import torch
from PIL import Image
from models.search_service import SearchServiceInterface

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class SemanticSearchService(SearchServiceInterface):
    """è¯­ä¹‰æœç´¢æœåŠ¡å®ç°"""
    
    def __init__(self, index_path: str = "image_index.faiss", metadata_path: str = "image_metadata.pkl"):
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.model_info_path = "model_info.pkl"  # æ–°å¢ï¼šå­˜å‚¨æ¨¡å‹ä¿¡æ¯
        
        # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self.current_model_name = "openai/clip-vit-base-patch32"
        
        # åŠ è½½æ–‡æœ¬ç¼–ç æ¨¡å‹
        self.text_encoder = SentenceTransformer('all-MiniLM-L6-v2')
        
        # åŠ è½½CLIPæ¨¡å‹ç”¨äºå›¾åƒç‰¹å¾æå–
        self.clip_model = CLIPModel.from_pretrained(self.current_model_name)
        self.clip_processor = CLIPProcessor.from_pretrained(self.current_model_name)
        self.clip_model.eval()
        
        # åˆå§‹åŒ–FAISSç´¢å¼•
        self.index = None
        self.image_metadata = {}  # å­˜å‚¨å›¾åƒå…ƒæ•°æ®
        self.image_paths = []  # å­˜å‚¨å›¾åƒè·¯å¾„åˆ—è¡¨ï¼Œç”¨äºç´¢å¼•æ˜ å°„
        
        # å°è¯•åŠ è½½ç°æœ‰çš„ç´¢å¼•
        self.load_index()
    
    def load_index(self):
        """åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•"""
        try:
            if os.path.exists(self.index_path) and os.path.exists(self.metadata_path):
                # æ£€æŸ¥æ¨¡å‹ä¿¡æ¯
                index_model_name = self._get_index_model_name()
                
                if index_model_name and index_model_name != self.current_model_name:
                    print(f"âš ï¸  æ£€æµ‹åˆ°æ¨¡å‹ä¸åŒ¹é…:")
                    print(f"   ç´¢å¼•æ¨¡å‹: {index_model_name}")
                    print(f"   å½“å‰æ¨¡å‹: {self.current_model_name}")
                    print("   éœ€è¦é‡æ–°æ„å»ºç´¢å¼•ä»¥ç¡®ä¿æœç´¢å‡†ç¡®æ€§")
                    
                    # åˆ›å»ºæ–°çš„ç©ºç´¢å¼•
                    dimension = 512
                    self.index = faiss.IndexFlatIP(dimension)
                    self.image_metadata = {}
                    self.image_paths = []
                    return
                
                # åŠ è½½ç´¢å¼•
                self.index = faiss.read_index(self.index_path)
                
                with open(self.metadata_path, 'rb') as f:
                    self.image_metadata = pickle.load(f)
                
                # é‡å»ºå›¾åƒè·¯å¾„åˆ—è¡¨
                self.image_paths = list(self.image_metadata.keys())
                
                print(f"ç´¢å¼•åŠ è½½æˆåŠŸï¼ŒåŒ…å« {self.index.ntotal} å¼ å›¾åƒï¼Œä½¿ç”¨æ¨¡å‹: {self.current_model_name}")
            else:
                print("æœªæ‰¾åˆ°ç°æœ‰ç´¢å¼•ï¼Œå°†åˆ›å»ºæ–°çš„ç´¢å¼•")
                # åˆ›å»ºæ–°çš„FAISSç´¢å¼•ï¼ˆCLIPæ¨¡å‹çš„ç‰¹å¾ç»´åº¦æ˜¯512ï¼‰
                dimension = 512
                self.index = faiss.IndexFlatIP(dimension)
        except Exception as e:
            print(f"åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
            # åˆ›å»ºæ–°çš„ç´¢å¼•
            dimension = 512
            self.index = faiss.IndexFlatIP(dimension)
    
    def save_index(self):
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        try:
            faiss.write_index(self.index, self.index_path)
            
            with open(self.metadata_path, 'wb') as f:
                pickle.dump(self.image_metadata, f)
            
            # ä¿å­˜æ¨¡å‹ä¿¡æ¯
            self._save_model_info()
            
            print(f"ç´¢å¼•å·²ä¿å­˜ï¼ŒåŒ…å« {self.index.ntotal} å¼ å›¾åƒï¼Œä½¿ç”¨æ¨¡å‹: {self.current_model_name}")
        except Exception as e:
            print(f"ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    def encode_text(self, text: str) -> np.ndarray:
        """å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡"""
        try:
            print(f"ç¼–ç æ–‡æœ¬: '{text}'")
            
            # æœ€ç®€åŒ–å¤„ç†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢æ–‡æœ¬ï¼Œä¸è¿›è¡Œä»»ä½•ç¿»è¯‘æˆ–è½¬æ¢
            # è¿™æ ·å¯ä»¥é¿å…æ‰€æœ‰æ½œåœ¨çš„é—®é¢˜
            inputs = self.clip_processor(text=[text], return_tensors="pt", padding=True)
            
            with torch.no_grad():
                text_features = self.clip_model.get_text_features(**inputs)
            
            # å°†ç‰¹å¾è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
            features = text_features.squeeze().cpu().numpy()
            features = features / np.linalg.norm(features)
            
            print(f"æ–‡æœ¬ç¼–ç å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {features.shape}, èŒƒæ•°: {np.linalg.norm(features):.4f}")
            return features.astype('float32')
            
        except Exception as e:
            print(f"æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return np.zeros(512, dtype='float32')  # è¿”å›é›¶å‘é‡
    
    def encode_image(self, image_path: str) -> np.ndarray:
        """å°†å›¾åƒç¼–ç ä¸ºå‘é‡"""
        try:
            image = Image.open(image_path).convert('RGB')
            inputs = self.clip_processor(images=image, return_tensors="pt")
            
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(**inputs)
            
            # å°†ç‰¹å¾è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
            features = image_features.squeeze().cpu().numpy()
            features = features / np.linalg.norm(features)
            return features.astype('float32')
        except Exception as e:
            print(f"å›¾åƒç¼–ç å¤±è´¥ {image_path}: {e}")
            return np.zeros(512, dtype='float32')  # è¿”å›é›¶å‘é‡
    
    def add_image(self, image_path: str) -> bool:
        """æ·»åŠ å›¾åƒåˆ°ç´¢å¼•"""
        try:
            # æ£€æŸ¥å›¾åƒæ˜¯å¦å·²å­˜åœ¨äºç´¢å¼•ä¸­
            if image_path in self.image_metadata:
                print(f"å›¾åƒå·²å­˜åœ¨äºç´¢å¼•ä¸­: {image_path}")
                return True
            
            # ç¼–ç å›¾åƒ
            features = self.encode_image(image_path)
            features = features.reshape(1, -1)  # è°ƒæ•´å½¢çŠ¶ä¸º (1, dimension)
            
            # æ·»åŠ åˆ°FAISSç´¢å¼•
            self.index.add(features)
            
            # ä¿å­˜å…ƒæ•°æ®
            from services.image_processor_service import ImageFeatureExtractor
            processor = ImageFeatureExtractor()
            metadata = processor.extract_metadata(image_path)
            self.image_metadata[image_path] = metadata
            self.image_paths.append(image_path)
            
            print(f"å›¾åƒå·²æ·»åŠ åˆ°ç´¢å¼•: {image_path}")
            return True
        except Exception as e:
            print(f"æ·»åŠ å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def remove_image(self, image_path: str) -> bool:
        """ä»ç´¢å¼•ä¸­ç§»é™¤å›¾åƒ"""
        try:
            if image_path not in self.image_metadata:
                print(f"å›¾åƒä¸åœ¨ç´¢å¼•ä¸­: {image_path}")
                return False
            
            # è·å–å›¾åƒåœ¨ç´¢å¼•ä¸­çš„ä½ç½®
            idx = self.image_paths.index(image_path)
            
            # ä»å…ƒæ•°æ®å’Œè·¯å¾„åˆ—è¡¨ä¸­ç§»é™¤
            del self.image_metadata[image_path]
            del self.image_paths[idx]
            
            # æ³¨æ„ï¼šFAISSä¸ç›´æ¥æ”¯æŒåˆ é™¤å‘é‡ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦é‡å»ºç´¢å¼•æˆ–ä½¿ç”¨å…¶ä»–ç­–ç•¥
            print(f"å›¾åƒå·²ä»ç´¢å¼•ä¸­ç§»é™¤: {image_path} (ç´¢å¼•é‡å»º)")
            
            # é‡å»ºç´¢å¼•
            self.rebuild_index()
            
            return True
        except Exception as e:
            print(f"ç§»é™¤å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def rebuild_index(self):
        """é‡å»ºç´¢å¼•ï¼ˆåœ¨åˆ é™¤å›¾åƒåï¼‰"""
        try:
            # ä¿å­˜å½“å‰ç´¢å¼•ä¸­çš„æ‰€æœ‰å‘é‡
            all_features = []
            for path in self.image_paths:
                features = self.encode_image(path)
                all_features.append(features)
            
            if all_features:
                # å †å æ‰€æœ‰ç‰¹å¾å‘é‡
                all_features = np.stack(all_features)
                
                # åˆ›å»ºæ–°ç´¢å¼•
                dimension = all_features.shape[1]
                new_index = faiss.IndexFlatIP(dimension)
                new_index.add(all_features)
                
                # æ›¿æ¢å½“å‰ç´¢å¼•
                self.index = new_index
            else:
                # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œåˆ›å»ºç©ºç´¢å¼•
                dimension = 512
                self.index = faiss.IndexFlatIP(dimension)
                
            print(f"ç´¢å¼•é‡å»ºå®Œæˆï¼ŒåŒ…å« {self.index.ntotal} å¼ å›¾åƒ")
        except Exception as e:
            print(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")
    
    def search_by_text(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """æ ¹æ®æ–‡æœ¬æœç´¢å›¾åƒ"""
        try:
            print(f"æœç´¢æŸ¥è¯¢: '{query}'")
            
            # ç¼–ç æŸ¥è¯¢æ–‡æœ¬
            query_vector = self.encode_text(query)
            if query_vector is None or np.allclose(query_vector, 0):
                print("è­¦å‘Š: æŸ¥è¯¢å‘é‡ä¸ºç©ºæˆ–å…¨é›¶")
                return []
                
            query_vector = query_vector.reshape(1, -1)  # è°ƒæ•´å½¢çŠ¶ä¸º (1, dimension)
            print(f"æŸ¥è¯¢å‘é‡ç»´åº¦: {query_vector.shape}, èŒƒæ•°: {np.linalg.norm(query_vector):.4f}")
            
            # åœ¨ç´¢å¼•ä¸­æœç´¢
            scores, indices = self.index.search(query_vector, min(top_k, self.index.ntotal))
            print(f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(indices[0])} ä¸ªç»“æœ")
            
            # æ„å»ºç»“æœ
            results = []
            for i in range(len(indices[0])):
                idx = int(indices[0][i])  # ç¡®ä¿è½¬æ¢ä¸ºPython int
                if idx < len(self.image_paths):
                    path = self.image_paths[idx]
                    similarity_score = float(scores[0][i])
                    print(f"ç»“æœ {i+1}: ç›¸ä¼¼åº¦={similarity_score:.4f}, è·¯å¾„={path}")
                    
                    metadata = self.image_metadata.get(path, {})
                    # ç¡®ä¿metadataä¸­çš„æ‰€æœ‰æ•°å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
                    serializable_metadata = {}
                    for key, value in metadata.items():
                        if isinstance(value, (np.integer, np.int64)):
                            serializable_metadata[key] = int(value)
                        elif isinstance(value, (np.floating, np.float64)):
                            serializable_metadata[key] = float(value)
                        else:
                            serializable_metadata[key] = value
                    
                    results.append({
                        "id": idx,
                        "path": path,
                        "similarity": similarity_score,
                        "metadata": serializable_metadata
                    })
            
            return results
        except Exception as e:
            print(f"æ–‡æœ¬æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def search_by_image(self, query_image_path: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """ä»¥å›¾æœå›¾"""
        try:
            print(f"ğŸ” å¼€å§‹ä»¥å›¾æœå›¾: {query_image_path}")
            print(f"ğŸ“Š å½“å‰ç´¢å¼•åŒ…å« {self.index.ntotal} å¼ å›¾åƒ")
            print(f"ğŸ“‹ å›¾åƒè·¯å¾„åˆ—è¡¨é•¿åº¦: {len(self.image_paths)}")
            
            # ç¼–ç æŸ¥è¯¢å›¾åƒ
            query_vector = self.encode_image(query_image_path)
            if query_vector is None:
                print("âŒ æŸ¥è¯¢å›¾åƒç¼–ç å¤±è´¥")
                return []
                
            query_vector = query_vector.reshape(1, -1)  # è°ƒæ•´å½¢çŠ¶ä¸º (1, dimension)
            print(f"ğŸ¯ æŸ¥è¯¢å‘é‡ç»´åº¦: {query_vector.shape}, èŒƒæ•°: {np.linalg.norm(query_vector):.4f}")
            
            # åœ¨ç´¢å¼•ä¸­æœç´¢
            scores, indices = self.index.search(query_vector, min(top_k, self.index.ntotal))
            print(f"ğŸ” æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(indices[0])} ä¸ªç»“æœ")
            
            # æ‰“å°å‰å‡ ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
            print("ğŸ“ˆ æœç´¢ç»“æœè¯¦æƒ…:")
            for i in range(min(5, len(indices[0]))):
                idx = int(indices[0][i])
                score = float(scores[0][i])
                if idx < len(self.image_paths):
                    path = self.image_paths[idx]
                    print(f"  {i+1}. ç´¢å¼•:{idx}, ç›¸ä¼¼åº¦:{score:.4f}, è·¯å¾„:{path}")
            
            # æ„å»ºç»“æœ
            results = []
            for i in range(len(indices[0])):
                idx = int(indices[0][i])  # ç¡®ä¿è½¬æ¢ä¸ºPython int
                if idx < len(self.image_paths):
                    path = self.image_paths[idx]
                    metadata = self.image_metadata.get(path, {})
                    # ç¡®ä¿metadataä¸­çš„æ‰€æœ‰æ•°å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
                    serializable_metadata = {}
                    for key, value in metadata.items():
                        if isinstance(value, (np.integer, np.int64)):
                            serializable_metadata[key] = int(value)
                        elif isinstance(value, (np.floating, np.float64)):
                            serializable_metadata[key] = float(value)
                        else:
                            serializable_metadata[key] = value
                    
                    results.append({
                        "id": idx,
                        "path": path,
                        "similarity": float(scores[0][i]),
                        "metadata": serializable_metadata
                    })
            
            print(f"âœ… è¿”å› {len(results)} ä¸ªæœç´¢ç»“æœ")
            return results
        except Exception as e:
            print(f"âŒ å›¾åƒæœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _get_model_path(self, model_name: str) -> str:
        """è·å–æ¨¡å‹çš„å®é™…è·¯å¾„"""
        model_mapping = {
            'clip-vit-base-patch32': "openai/clip-vit-base-patch32",
            'clip-vit-large-patch14': "openai/clip-vit-large-patch14", 
            'chinese-clip-vit-base-patch16': "OFA-Sys/chinese-clip-vit-base-patch16",
            'multilingual-clip-vit-base-patch32': "sentence-transformers/clip-ViT-B-32-multilingual-v1",
            'blip-base': "Salesforce/blip-image-captioning-base"
        }
        return model_mapping.get(model_name, "openai/clip-vit-base-patch32")
    
    def _save_model_info(self):
        """ä¿å­˜å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
        try:
            model_info = {
                'model_name': self.current_model_name,
                'timestamp': time.time()
            }
            with open(self.model_info_path, 'wb') as f:
                pickle.dump(model_info, f)
        except Exception as e:
            print(f"ä¿å­˜æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
    
    def _get_index_model_name(self) -> str:
        """è·å–ç´¢å¼•ä½¿ç”¨çš„æ¨¡å‹åç§°"""
        try:
            if os.path.exists(self.model_info_path):
                with open(self.model_info_path, 'rb') as f:
                    model_info = pickle.load(f)
                return model_info.get('model_name', '')
            return ''
        except Exception as e:
            print(f"è¯»å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
            return ''

    def set_model(self, model_name: str):
        """è®¾ç½®ä½¿ç”¨çš„æ¨¡å‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢æ¨¡å‹
            if model_name == self.current_model_name:
                print(f"æ¨¡å‹å·²ç»æ˜¯ {model_name}ï¼Œæ— éœ€åˆ‡æ¢")
                return
            
            # è·å–æ¨¡å‹è·¯å¾„
            model_path = self._get_model_path(model_name)
            
            print(f"æ­£åœ¨åˆ‡æ¢æ¨¡å‹: {self.current_model_name} -> {model_name}")
            
            # åŠ è½½æ–°æ¨¡å‹
            if model_name == 'blip-base':
                print("BLIPæ¨¡å‹æ”¯æŒå°†åœ¨åç»­ç‰ˆæœ¬ä¸­æ·»åŠ ")
                return
            elif model_name == 'chinese-clip-vit-base-patch16':
                # ä½¿ç”¨Chinese CLIPä¸“ç”¨çš„ç±»å’Œå¤„ç†å™¨
                self.clip_model = ChineseCLIPModel.from_pretrained(model_path)
                self.clip_processor = ChineseCLIPProcessor.from_pretrained(model_path)
            else:
                # ä½¿ç”¨æ ‡å‡†CLIPæ¨¡å‹
                self.clip_model = CLIPModel.from_pretrained(model_path)
                self.clip_processor = CLIPProcessor.from_pretrained(model_path)
            
            # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
            self.clip_model.eval()
            
            # æ›´æ–°å½“å‰æ¨¡å‹åç§°
            old_model = self.current_model_name
            self.current_model_name = model_path
            
            print(f"âœ… æˆåŠŸåˆ‡æ¢æ¨¡å‹: {model_name}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•
            if self.index.ntotal > 0:
                print("âš ï¸  æ£€æµ‹åˆ°ç°æœ‰ç´¢å¼•ï¼Œå»ºè®®é‡æ–°ç´¢å¼•å›¾ç‰‡ä»¥ç¡®ä¿æœç´¢å‡†ç¡®æ€§")
                print("   å¯ä»¥è°ƒç”¨ rebuild_index_with_new_model() æ–¹æ³•é‡å»ºç´¢å¼•")
            
        except Exception as e:
            print(f"è®¾ç½®æ¨¡å‹å¤±è´¥: {e}")
            # æ¢å¤åˆ°åŸæ¥çš„æ¨¡å‹
            self.current_model_name = old_model if 'old_model' in locals() else self.current_model_name
    
    def rebuild_index_with_new_model(self):
        """ä½¿ç”¨æ–°æ¨¡å‹é‡å»ºæ•´ä¸ªç´¢å¼•"""
        try:
            if not self.image_paths:
                print("æ²¡æœ‰å›¾ç‰‡éœ€è¦é‡å»ºç´¢å¼•")
                return
            
            print(f"å¼€å§‹ä½¿ç”¨æ¨¡å‹ {self.current_model_name} é‡å»ºç´¢å¼•...")
            
            # ä¿å­˜å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            paths_to_rebuild = self.image_paths.copy()
            
            # æ¸…ç©ºå½“å‰ç´¢å¼•
            dimension = 512
            self.index = faiss.IndexFlatIP(dimension)
            self.image_paths = []
            
            # é‡æ–°ç¼–ç æ‰€æœ‰å›¾ç‰‡
            success_count = 0
            for i, image_path in enumerate(paths_to_rebuild):
                try:
                    if os.path.exists(image_path):
                        # é‡æ–°ç¼–ç å¹¶æ·»åŠ åˆ°ç´¢å¼•
                        features = self.encode_image(image_path)
                        features = features.reshape(1, -1)
                        self.index.add(features)
                        self.image_paths.append(image_path)
                        success_count += 1
                        
                        if (i + 1) % 10 == 0:
                            print(f"å·²é‡å»º {i + 1}/{len(paths_to_rebuild)} å¼ å›¾ç‰‡")
                    else:
                        print(f"å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {image_path}")
                        # ä»å…ƒæ•°æ®ä¸­ç§»é™¤
                        if image_path in self.image_metadata:
                            del self.image_metadata[image_path]
                            
                except Exception as e:
                    print(f"é‡å»ºå›¾ç‰‡ç´¢å¼•å¤±è´¥ {image_path}: {e}")
            
            print(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼æˆåŠŸé‡å»º {success_count} å¼ å›¾ç‰‡")
            
            # ä¿å­˜æ–°ç´¢å¼•
            self.save_index()
            
        except Exception as e:
            print(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")
    
    def rebuild_index_with_new_model_progress(self, task_id: str, processing_status: dict):
        """ä½¿ç”¨æ–°æ¨¡å‹é‡å»ºæ•´ä¸ªç´¢å¼•ï¼ˆå¸¦è¿›åº¦æ›´æ–°ï¼‰"""
        try:
            if not self.image_paths:
                print("æ²¡æœ‰å›¾ç‰‡éœ€è¦é‡å»ºç´¢å¼•")
                return
            
            print(f"å¼€å§‹ä½¿ç”¨æ¨¡å‹ {self.current_model_name} é‡å»ºç´¢å¼•...")
            
            # ä¿å­˜å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            paths_to_rebuild = self.image_paths.copy()
            total_images = len(paths_to_rebuild)
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            processing_status[task_id]["total"] = total_images
            
            # æ¸…ç©ºå½“å‰ç´¢å¼•
            dimension = 512
            self.index = faiss.IndexFlatIP(dimension)
            self.image_paths = []
            
            # é‡æ–°ç¼–ç æ‰€æœ‰å›¾ç‰‡
            success_count = 0
            for i, image_path in enumerate(paths_to_rebuild):
                try:
                    if os.path.exists(image_path):
                        # é‡æ–°ç¼–ç å¹¶æ·»åŠ åˆ°ç´¢å¼•
                        features = self.encode_image(image_path)
                        features = features.reshape(1, -1)
                        self.index.add(features)
                        self.image_paths.append(image_path)
                        success_count += 1
                        
                        # æ›´æ–°è¿›åº¦
                        processing_status[task_id]["processed"] = i + 1
                        processing_status[task_id]["progress"] = int((i + 1) / total_images * 100)
                        
                        if (i + 1) % 5 == 0:
                            print(f"å·²é‡å»º {i + 1}/{total_images} å¼ å›¾ç‰‡")
                    else:
                        print(f"å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {image_path}")
                        # ä»å…ƒæ•°æ®ä¸­ç§»é™¤
                        if image_path in self.image_metadata:
                            del self.image_metadata[image_path]
                            
                except Exception as e:
                    print(f"é‡å»ºå›¾ç‰‡ç´¢å¼•å¤±è´¥ {image_path}: {e}")
            
            print(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼æˆåŠŸé‡å»º {success_count} å¼ å›¾ç‰‡")
            
            # ä¿å­˜æ–°ç´¢å¼•
            self.save_index()
            
        except Exception as e:
            print(f"é‡å»ºç´¢å¼•å¤±è´¥: {e}")